{% extends "layout.html" %}
{% block content %}

<img src="static/images/img1.png" alt="Car" style="width:100%;height:300px">

    <div class="w3-card-4 w3-margin">

        <header class="w3-container w3-blue">
          <h1>Introduction</h1>
        </header>
        
        <div class="w3-container">
          <p>Deepfakes can be used to mislead the public, harm reputations, and undermine trust in legitimate sources of information. 
            High-profile cases have demonstrated the potential of deepfakes to influence elections, incite social unrest, and damage 
            personal and professional reputations. As deepfake creation tools become more accessible, the urgency for effective detection 
            methods has never been greater.<br> 
            By utilizing state-of-the-art techniques such as convolutional neural networks (CNNs) for image feature extraction and recurrent 
            neural networks (RNNs) or transformers for face detection, we aim to build a robust model capable of delivering meaningful and 
            relevant descriptions. The project will also emphasize user-centric design, incorporating feedback from deepfake face 
            individuals to ensure that the generated captions are not only accurate but also contextually helpful.
	        </p>
        </div>
        
        <footer class="w3-container w3-blue">
          <h5></h5>
        </footer>
        
        </div>

        <div class="w3-card-4 w3-margin">

            <header class="w3-container w3-blue">
              <h1>About The Project</h1>
            </header>
            
            <div class="w3-container">
              <p>
                The "Deepfake face Detection" project aims to develop a system that automatically generates 
                descriptive analysis for images, enhancing accessibility for visually impaired individuals. By employing machine 
                learning and deep learning techniques—specifically convolutional neural networks (CNNs) for image analysis and 
                recurrent neural networks (RNNs) or transformers for text generation—the project seeks to accurately interpret 
                visual content and translate it into meaningful text. User feedback will play a crucial role in refining the model 
                to ensure that the captions are relevant and helpful. Ultimately, this initiative aims to empower visually impaired 
                users by providing them with a better understanding of their environment, fostering inclusivity and independence 
                through innovative technology.
              </p>
            </div>
            
            <footer class="w3-container w3-blue">
              <h5></h5>
            </footer>
            
            </div>

    <div class="w3-container w3-center">
        <h2>Architecture Diagram</h2>
        <img src="static/images/Arch.png" alt="car" style="width:100%">
      </div>

{% endblock %}